\chapter{Deterministic Systems and the Shortest Path Problem}
In this chapter we focus on deterministic problems, i.e., $w_k$ can take only one value. In contrast with stochastic problems, \textit{using feedback results in no advantage in terms of cost reduction.} 

\section{Finite-State Systems and Shortest Paths}
The DP algorithm takes the form 
\begin{equation}
    J_N(i)=a_{it}^N,\quad i\in S_N,
\end{equation}
\begin{equation}
    J_k(i)=\min_{j\in S_{k+1}}\left[a_{ij}^k+J_{k+1}(j)\right],\quad i\in S_k,\quad k=0,1,\dots,N-1.
\end{equation}
\subsection*{A Forward DP Algorithm for Shortest Path Problems}
An optimal path from $s$ to $t$ is also an optimal path from $t$ to $s$ in a "reverse" shortest path problem. It is given by 
\begin{align}
    &\tilde{J}_N(j)=a_{sj}^0,\quad j\in S_1,\\
    &\tilde{J}_k(j)=\min_{i\in S_{N-k}}\left[a_{ij}^{N-k}+\title{J}_{k+1}(i)\right],\quad j\in S_{N-k+1},\quad k=1,2,\dots,N-1.
\end{align}
The optimal cost is 
\[\tilde{J}_0(t)=\min_{i\in S_N}\left[a_{ij}^N+\tilde{J}_1(i)\right].\]
The above equations yield the same result
\[J_0(s) =\tilde{J}_0(t).\]
Note that there is no analog of forward DP algorithm for stochastic problems.

\subsection*{Converting a Shortest Path Problem to a Deterministic Finite-Stage Problem}

\section{Some Shortest Path Applications}
\subsection{Critical Path Analysis}
\subsection{Hidden Markov Models and the Vaterbi Algorithm}
We are given the probability $r(z;i,j)$ of an observation taking value $z$ when the state transition is from $i$ to $j$. We assume independent observations; i.e., an observation depends only on its corresponding transition and not on other transitions. Time independent. $\pi$ initial state's probability. 

Given the observation sequence $Z_N=\{z_1,z_2,\dots,z_N\}$, we adopt $\hat{X}_N=\{\hat{x}_0,\hat{x}_1,\dots,\hat{x}_N\}$ that maximizes over all $X_N=\{x_1,x_2,\dots,x_N\}$ the conditional probability $p(X_N|Z_N)$. This is called the \textit{maximum a posteriori probability} approach.

Using independence, we have 
\begin{equation}
    p(X_N,Z_N) =\pi_{x_0}\prod_{k = 1}^N\, p_{x_{k - 1}x_k} r(z_k;x_{k - 1},x_k)
\end{equation}

\textit{Trellis diagram and Viterbi algorithm.}

The problem of maximizing $p(X_N,Z_N)$ is equivalent to the problem 
\begin{align*}
    &\text{minimize }-\ln \left(\pi_{x_0}\right)-\sum_{k=1}^N \ln
    \left(p_{x_{k-1} x_k} r\left(z_k ; x_{k-1}, x_k\right)\right)\, \\
    &\text{over all possible sequences} \left\{x_0, x_1, \ldots, x_N\right\}.
\end{align*}

% \begin{example}[(Convolutional Coding and Decoding)]\label{example:2.2.1}
%     test
% \end{example}
\section{Shortest Path Algorithms}
 To be continued.
 